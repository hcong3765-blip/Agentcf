# ========== å¯¼å…¥æ¨¡å—éƒ¨åˆ† ==========
import os, numpy as np                            # åŸºç¡€åº“
from tqdm import tqdm                             # è¿›åº¦æ¡
import torch                                      # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
from recbole.trainer import Trainer               # RecBoleåŸºç¡€è®­ç»ƒå™¨
from recbole.utils import EvaluatorType, set_color, early_stopping, dict2str, get_gpu_usage
from recbole.data.interaction import Interaction  # RecBoleäº¤äº’æ•°æ®ç±»
from time import time                             # æ—¶é—´åŠŸèƒ½

class LanguageLossTrainer(Trainer):
    """
    è¯­è¨€æŸå¤±è®­ç»ƒå™¨ï¼šç»§æ‰¿è‡ªRecBoleçš„Trainerç±»
    ğŸ’¡è¯­æ³•è§£é‡Šï¼šclass ClassName(ParentClass)è¡¨ç¤ºç±»ç»§æ‰¿
    ä¸“é—¨ç”¨äºå¤„ç†åŸºäºè¯­è¨€æ¨¡å‹çš„æ¨èç³»ç»Ÿè®­ç»ƒ
    """
    
    def __init__(self, config, model, dataset):
        """
        åˆå§‹åŒ–å‡½æ•°
        ğŸ’¡è¯­æ³•è§£é‡Šï¼š__init__æ˜¯Pythonçš„æ„é€ å‡½æ•°ï¼Œåˆ›å»ºå¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨
        """
        super().__init__(config, model)           # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šsuper()è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼Œä¿æŒç»§æ‰¿é“¾çš„å®Œæ•´æ€§
        
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°
        self.sampled_user_suffix = config['sampled_user_suffix']    # å€™é€‰ç”Ÿæˆæ¨¡å‹åç¼€
        self.recall_budget = config['recall_budget']                # å€™é€‰é›†å¤§å°ï¼Œé»˜è®¤20
        self.fix_pos = config['fix_pos']                            # æ­£æ ·æœ¬ä½ç½®ï¼Œé»˜è®¤-1
        
        # åŠ è½½å·²é€‰æ‹©çš„ç‰©å“
        self.user2sampled_item = self.load_selected_items(config, dataset)

    def load_selected_items(self, config, dataset):
        """
        åŠ è½½ç”¨æˆ·çš„é¢„é€‰ç‰©å“åˆ—è¡¨
        è¿™ä¸ªå‡½æ•°è¯»å–æ–‡ä»¶ï¼Œå»ºç«‹ç”¨æˆ·åˆ°å€™é€‰ç‰©å“çš„æ˜ å°„
        """
        # æ„é€ é‡‡æ ·ç‰©å“æ–‡ä»¶è·¯å¾„
        sampled_item_file = os.path.join(config['data_path'], f'{config["dataset"]}.{self.sampled_user_suffix}')
        
        # è·å–ç”¨æˆ·å’Œç‰©å“çš„tokenæ˜ å°„
        user_token2id = dataset.field2token_id['user_id']     # ç”¨æˆ·tokenåˆ°IDçš„æ˜ å°„
        item_token2id = dataset.field2token_id['item_id']     # ç‰©å“tokenåˆ°IDçš„æ˜ å°„
        
        user2sampled_item = {}                    # ç”¨æˆ·åˆ°é‡‡æ ·ç‰©å“çš„å­—å…¸
        
        # è¯»å–æ–‡ä»¶å¹¶è§£æ
        with open(sampled_item_file, 'r', encoding='utf-8') as file:
            for line in file:                     # é€è¡Œè¯»å–
                uid, iid_list = line.strip().split('\t')              # æŒ‰åˆ¶è¡¨ç¬¦åˆ†å‰²
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼šsplit('\t')æŒ‰åˆ¶è¡¨ç¬¦åˆ†å‰²å­—ç¬¦ä¸²ï¼Œstrip()å»é™¤é¦–å°¾ç©ºç™½
                user2sampled_item[user_token2id[uid]] = [item_token2id[_] for _ in iid_list.split(' ')]
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼šåˆ—è¡¨æ¨å¯¼å¼[expression for item in iterable]
        
        return user2sampled_item

    @torch.no_grad()                             # è£…é¥°å™¨ï¼šç¦ç”¨æ¢¯åº¦è®¡ç®—
    def evaluate(self, eval_data, load_best_model=True, model_file=None, show_progress=False):
        """
        è¯„ä¼°å‡½æ•°ï¼šè®¡ç®—æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
        ğŸ’¡è¯­æ³•è§£é‡Šï¼š@torch.no_grad()æ˜¯è£…é¥°å™¨ï¼Œè¡¨ç¤ºå‡½æ•°å†…ä¸è®¡ç®—æ¢¯åº¦ï¼ˆèŠ‚çœå†…å­˜ï¼‰
        """
        eval_func = self._full_sort_batch_eval    # é€‰æ‹©è¯„ä¼°å‡½æ•°
        
        # å¦‚æœéœ€è¦åŠ è½½æœ€ä½³æ¨¡å‹
        if load_best_model:
            checkpoint_file = model_file or self.saved_model_file  # ä½¿ç”¨æŒ‡å®šæ–‡ä»¶æˆ–é»˜è®¤æ–‡ä»¶
            checkpoint = torch.load(checkpoint_file, map_location=self.device, weights_only=False)  # åŠ è½½æ£€æŸ¥ç‚¹
            # ğŸ’¡è¯­æ³•è§£é‡Šï¼šmap_locationæŒ‡å®šåŠ è½½åˆ°çš„è®¾å¤‡ï¼Œé¿å…GPU/CPUå†²çª
            
            # åŠ è½½æ¨¡å‹å‚æ•°
            if "state_dict" in checkpoint:
                self.model.load_state_dict(checkpoint["state_dict"])
            elif "model_state_dict" in checkpoint:
                self.model.load_state_dict(checkpoint["model_state_dict"])
            else:
                self.logger.warning("âš ï¸ Checkpointä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹çŠ¶æ€å­—å…¸")
            
            # åŠ è½½æ™ºèƒ½ä½“çŠ¶æ€
            if 'user_agents' in checkpoint and hasattr(self.model, 'user_agents'):
                try:
                    self.model.user_agents = checkpoint['user_agents']
                    self.logger.info(f'âœ… è¯„ä¼°æ—¶åŠ è½½ç”¨æˆ·æ™ºèƒ½ä½“çŠ¶æ€: {len(self.model.user_agents)} ä¸ªæ™ºèƒ½ä½“')
                except Exception as agent_error:
                    self.logger.warning(f"âš ï¸ è¯„ä¼°æ—¶åŠ è½½ç”¨æˆ·æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")
            
            if 'item_agents' in checkpoint and hasattr(self.model, 'item_agents'):
                try:
                    self.model.item_agents = checkpoint['item_agents']
                    self.logger.info(f'âœ… è¯„ä¼°æ—¶åŠ è½½ç‰©å“æ™ºèƒ½ä½“çŠ¶æ€: {len(self.model.item_agents)} ä¸ªæ™ºèƒ½ä½“')
                except Exception as agent_error:
                    self.logger.warning(f"âš ï¸ è¯„ä¼°æ—¶åŠ è½½ç‰©å“æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")
            
            if 'embedding_agent' in checkpoint and hasattr(self.model, 'embedding_agent'):
                try:
                    self.model.embedding_agent = checkpoint['embedding_agent']
                    self.logger.info(f'âœ… è¯„ä¼°æ—¶åŠ è½½åµŒå…¥æ™ºèƒ½ä½“çŠ¶æ€')
                except Exception as agent_error:
                    self.logger.warning(f"âš ï¸ è¯„ä¼°æ—¶åŠ è½½åµŒå…¥æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")
            
            message_output = "Loading model structure and parameters from {}".format(checkpoint_file)
            self.logger.info(message_output)

        self.model.eval()                         # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šmodel.eval()å…³é—­dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
        
        if self.config["eval_type"] == EvaluatorType.RANKING:
            self.tot_item_num = eval_data._dataset.item_num

        # åˆ›å»ºè¿›åº¦æ¡ï¼ˆå¦‚æœéœ€è¦æ˜¾ç¤ºï¼‰
        iter_data = (
            tqdm(eval_data, total=len(eval_data), ncols=100, desc=set_color(f"Evaluate   ", "pink"))
            if show_progress else eval_data
        )
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šä¸‰å…ƒè¿ç®—ç¬¦ A if condition else B

        # å¼€å§‹è¯„ä¼°å¾ªç¯
        for batch_idx, batched_data in enumerate(iter_data):
            interaction, history_index, positive_u, positive_i = batched_data
            
            sampled_items = []                    # å­˜å‚¨é‡‡æ ·ç‰©å“
            for i in range(len(interaction)):     # éå†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªç”¨æˆ·
                user_id = int(interaction['user_id'][i].item())  # è·å–ç”¨æˆ·ID
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼š.item()å°†tensorè½¬æ¢ä¸ºPythonæ ‡é‡
                sampled_item = self.user2sampled_item[user_id]   # è·å–ç”¨æˆ·çš„å€™é€‰ç‰©å“
                sampled_items.append(sampled_item)
            
            sampled_items = torch.LongTensor(sampled_items)      # è½¬æ¢ä¸ºtensor

            # å¤„ç†ground truthï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if self.config['has_gt']:
                self.logger.info('Has ground truth')
                idxs = torch.LongTensor(sampled_items)
                
                # ä»å€™é€‰ä¸­ç§»é™¤æ­£æ ·æœ¬ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
                for i in range(idxs.shape[0]):
                    if positive_i[i] in idxs[i]:               # å¦‚æœæ­£æ ·æœ¬åœ¨å€™é€‰ä¸­
                        pr = idxs[i].cpu().numpy().tolist().index(positive_i[i].item())
                        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šé“¾å¼è°ƒç”¨ tensor.cpu().numpy().tolist()
                        idxs[i][pr:-1] = torch.clone(idxs[i][pr+1:])  # ç§»é™¤æ­£æ ·æœ¬
                
                # æˆªå–åˆ°é¢„ç®—å¤§å°
                idxs = idxs[:,:self.recall_budget - 1]
                
                # æ ¹æ®å›ºå®šä½ç½®è®¾ç½®é‡æ–°æ’å…¥æ­£æ ·æœ¬
                if self.fix_pos == -1 or self.fix_pos == self.recall_budget - 1:
                    idxs = torch.cat([idxs, positive_i.unsqueeze(-1)], dim=-1).numpy()
                    # ğŸ’¡è¯­æ³•è§£é‡Šï¼štorch.cat()æ‹¼æ¥tensorï¼Œunsqueeze(-1)å¢åŠ æœ€åä¸€ä¸ªç»´åº¦
                elif self.fix_pos == 0:
                    idxs = torch.cat([positive_i.unsqueeze(-1), idxs], dim=-1).numpy()
                else:
                    idxs_a, idxs_b = torch.split(idxs, (self.fix_pos, self.recall_budget - 1 - self.fix_pos), dim=-1)
                    # ğŸ’¡è¯­æ³•è§£é‡Šï¼štorch.split()æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²tensor
                    idxs = torch.cat([idxs_a, positive_i.unsqueeze(-1), idxs_b], dim=-1).numpy()
            else:
                self.logger.info('Does not have ground truth.')
                idxs = torch.LongTensor(self.sampled_items)
                idxs = idxs[:,:self.recall_budget].numpy()

            # å¦‚æœéœ€è¦éšæœºæ‰“ä¹±ground truthä½ç½®
            if self.fix_pos == -1:
                self.logger.info('Shuffle ground truth')
                for i in range(idxs.shape[0]):
                    np.random.shuffle(idxs[i])    # éšæœºæ‰“ä¹±æ•°ç»„

            idxs = torch.LongTensor(idxs)
            
            # æ‰§è¡Œæ‰¹æ¬¡è¯„ä¼°
            interaction, scores, positive_u, positive_i = eval_func(batched_data, idxs)
            
            # æ”¶é›†è¯„ä¼°ç»“æœ
            self.eval_collector.eval_batch_collect(scores, interaction, positive_u, positive_i)
        
        # æ¨¡å‹æ”¶é›†å’Œæœ€ç»ˆè¯„ä¼°
        self.eval_collector.model_collect(self.model)
        struct = self.eval_collector.get_data_struct()
        result = self.evaluator.evaluate(struct)
        self.wandblogger.log_eval_metrics(result, head="eval")
        
        return result

    def _full_sort_batch_eval(self, batched_data, sampled_items):
        """
        å…¨æ’åºæ‰¹æ¬¡è¯„ä¼°ï¼šå¯¹å€™é€‰ç‰©å“è¿›è¡Œæ‰“åˆ†æ’åº
        """
        interaction, history_index, positive_u, positive_i = batched_data
        
        try:
            # å°è¯•ä½¿ç”¨æ¨¡å‹çš„å…¨æ’åºé¢„æµ‹åŠŸèƒ½
            scores = self.model.full_sort_predict(interaction.to(self.device), sampled_items.to(self.device))
        except NotImplementedError:
            # å¦‚æœæ¨¡å‹æ²¡æœ‰å®ç°å…¨æ’åºï¼Œåˆ™ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            inter_len = len(interaction)
            new_inter = interaction.to(self.device).repeat_interleave(self.tot_item_num)
            # ğŸ’¡è¯­æ³•è§£é‡Šï¼šrepeat_interleave()é‡å¤å¼ é‡å…ƒç´ 
            batch_size = len(new_inter)
            new_inter.update(self.item_tensor.repeat(inter_len))

            # æ ¹æ®æ‰¹æ¬¡å¤§å°é€‰æ‹©é¢„æµ‹æ–¹å¼
            if batch_size <= self.test_batch_size:
                scores = self.model.predict(new_inter)
            else:
                scores = self._spilt_predict(new_inter, batch_size)

        # é‡å¡‘åˆ†æ•°çŸ©é˜µ
        scores = scores.view(-1, self.tot_item_num)
        scores[:, 0] = -np.inf                    # å°†paddingé¡¹è®¾ä¸ºè´Ÿæ— ç©·
        
        # å±è”½å†å²äº¤äº’ç‰©å“
        if history_index is not None:
            scores[history_index] = -np.inf
        
        return interaction, scores, positive_u, positive_i

    def fit(self, train_data, valid_data=None, verbose=True, saved=True, show_progress=False, callback_fn=None, resume_epoch=None):
        """
        è®­ç»ƒå‡½æ•°ï¼šæ‰§è¡Œæ¨¡å‹è®­ç»ƒè¿‡ç¨‹
        ğŸ’¡è¿™æ˜¯ç®€åŒ–ç‰ˆçš„è®­ç»ƒå‡½æ•°ï¼Œä¸»è¦ç”¨äºAgentCFçš„ç‰¹æ®Šè®­ç»ƒéœ€æ±‚
        Args:
            resume_epoch: ä»æŒ‡å®šepochå¼€å§‹è®­ç»ƒï¼Œå¦‚æœä¸ºNoneåˆ™ä»å¤´å¼€å§‹
        """
        # è®¾ç½®èµ·å§‹epoch
        start_epoch = resume_epoch if resume_epoch is not None else self.start_epoch

        # å¦‚æœå·²ç»è®­ç»ƒå®Œæˆä¸”éœ€è¦ä¿å­˜
        if saved and start_epoch >= self.epochs:
            self._save_checkpoint(-1, verbose=verbose)

        # æ•°æ®æ”¶é›†
        self.eval_collector.data_collect(train_data)

        # åŠ¨æ€è´Ÿé‡‡æ ·è®¾ç½®
        if self.config["train_neg_sample_args"].get("dynamic", False):
            train_data.get_model(self.model)

        valid_step = 0

        # è®­ç»ƒå¾ªç¯
        for epoch_idx in range(start_epoch, self.epochs):
            try:
                # è®­ç»ƒä¸€ä¸ªepoch
                train_loss = self._train_epoch(train_data, epoch_idx, show_progress=show_progress)

                # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœ‰save_checkpointæ–¹æ³•ï¼‰
                if hasattr(self, 'save_checkpoint'):
                    self.save_checkpoint(epoch_idx, verbose=verbose)
                elif saved:
                    # å¦‚æœæ²¡æœ‰save_checkpointæ–¹æ³•ï¼Œæ‰‹åŠ¨ä¿å­˜
                    self._manual_save_checkpoint(epoch_idx, verbose=verbose)

            except Exception as e:
                # æ‰“å°é”™è¯¯ä¿¡æ¯ä½†ç»§ç»­è®­ç»ƒ
                self.logger.error(f"âŒ Epoch {epoch_idx} è®­ç»ƒå¤±è´¥: {str(e)}")
                self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")

                # å³ä½¿å‡ºç°é”™è¯¯ä¹Ÿå°è¯•ä¿å­˜æ£€æŸ¥ç‚¹
                try:
                    if saved:
                        self._manual_save_checkpoint(epoch_idx, verbose=False)
                        self.logger.info(f"âœ… å·²ä¿å­˜epoch {epoch_idx}çš„æ£€æŸ¥ç‚¹")
                except Exception as save_error:
                    self.logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {str(save_error)}")

                # ç»§ç»­ä¸‹ä¸€ä¸ªepoch
                self.logger.info(f"ğŸ”„ ç»§ç»­è®­ç»ƒä¸‹ä¸€ä¸ªepoch...")
                continue

    def _train_epoch(self, train_data, epoch_idx, loss_func=None, show_progress=False):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        ğŸ’¡epochæ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„æ¦‚å¿µï¼Œè¡¨ç¤ºå¯¹æ•´ä¸ªè®­ç»ƒé›†è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„éå†
        """
        self.model.train()                        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        loss_func = loss_func or self.model.calculate_loss  # é€‰æ‹©æŸå¤±å‡½æ•°
        total_loss = None

        # åˆ›å»ºæ•°æ®è¿­ä»£å™¨ï¼ˆå¸¦æˆ–ä¸å¸¦è¿›åº¦æ¡ï¼‰
        iter_data = (
            tqdm(train_data, total=len(train_data), ncols=100, 
                 desc=set_color(f"Train {epoch_idx:>5}", "pink"))
            if show_progress else train_data
        )

        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒçš„epoch
        if not self.config["single_spec"] and train_data.shuffle:
            train_data.sampler.set_epoch(epoch_idx)

        # è®­ç»ƒå¾ªç¯
        for batch_idx, interaction in enumerate(iter_data):
            try:
                interaction = interaction.to(self.device)  # å°†æ•°æ®ç§»åˆ°æŒ‡å®šè®¾å¤‡

                # æ˜¾ç¤ºGPUä½¿ç”¨æƒ…å†µ
                if self.gpu_available and show_progress:
                    iter_data.set_postfix_str(
                        set_color("GPU RAM: " + get_gpu_usage(self.device), "yellow")
                    )

                # è®¡ç®—æŸå¤±ï¼ˆè¿™é‡Œè°ƒç”¨æ¨¡å‹çš„calculate_lossæ–¹æ³•ï¼‰
                loss_func(interaction)

            except Exception as e:
                # æ‰“å°batchçº§åˆ«çš„é”™è¯¯ä¿¡æ¯ä½†ç»§ç»­è®­ç»ƒ
                self.logger.error(f"âŒ Batch {batch_idx} (Epoch {epoch_idx}) å¤„ç†å¤±è´¥: {str(e)}")
                self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")

                # è®°å½•äº¤äº’æ•°æ®çš„åŸºæœ¬ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                try:
                    if hasattr(interaction, 'shape'):
                        self.logger.error(f"äº¤äº’æ•°æ®shape: {interaction.shape}")
                    elif hasattr(interaction, '__len__'):
                        self.logger.error(f"äº¤äº’æ•°æ®é•¿åº¦: {len(interaction)}")
                    else:
                        self.logger.error(f"äº¤äº’æ•°æ®ç±»å‹: {type(interaction)}")
                except Exception as info_error:
                    self.logger.error(f"æ— æ³•è·å–äº¤äº’æ•°æ®ä¿¡æ¯: {str(info_error)}")

                # ç»§ç»­ä¸‹ä¸€ä¸ªbatch
                self.logger.info(f"ğŸ”„ è·³è¿‡æœ‰é—®é¢˜çš„batch {batch_idx}ï¼Œç»§ç»­è®­ç»ƒ...")
                continue

        return total_loss

    def _manual_save_checkpoint(self, epoch_idx, verbose=True):
        """
        æ‰‹åŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼ŒåŒ…å«æ™ºèƒ½ä½“çŠ¶æ€å’Œæ—¶é—´æˆ³
        """
        import os
        import torch
        from datetime import datetime

        try:
            # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„checkpointç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_dir = os.path.join(self.config['checkpoint_dir'], self.config['model'], f"run_{timestamp}")
            os.makedirs(checkpoint_dir, exist_ok=True)

            # ä¿å­˜æ¨¡å‹çŠ¶æ€
            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch_idx}.pth')
            
            # æ„å»ºcheckpointå­—å…¸ï¼ŒåŒ…å«æ™ºèƒ½ä½“çŠ¶æ€
            checkpoint = {
                'epoch': epoch_idx,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': getattr(self, 'optimizer', {}).state_dict() if hasattr(self, 'optimizer') else None,
                'config': self.config,
                'timestamp': timestamp,
            }
            
            # ä¿å­˜æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆå¦‚æœæ¨¡å‹æœ‰è¿™äº›å±æ€§ï¼‰
            if hasattr(self.model, 'user_agents'):
                checkpoint['user_agents'] = self.model.user_agents
                if verbose:
                    self.logger.info(f"ğŸ’¾ ä¿å­˜ç”¨æˆ·æ™ºèƒ½ä½“çŠ¶æ€: {len(self.model.user_agents)} ä¸ªæ™ºèƒ½ä½“")
            
            if hasattr(self.model, 'item_agents'):
                checkpoint['item_agents'] = self.model.item_agents
                if verbose:
                    self.logger.info(f"ğŸ’¾ ä¿å­˜ç‰©å“æ™ºèƒ½ä½“çŠ¶æ€: {len(self.model.item_agents)} ä¸ªæ™ºèƒ½ä½“")
            
            if hasattr(self.model, 'embedding_agent'):
                checkpoint['embedding_agent'] = self.model.embedding_agent
                if verbose:
                    self.logger.info("ğŸ’¾ ä¿å­˜åµŒå…¥æ™ºèƒ½ä½“çŠ¶æ€")

            torch.save(checkpoint, checkpoint_path)

            if verbose:
                self.logger.info(f'âœ… Checkpoint saved to {checkpoint_path}')
                self.logger.info(f'ğŸ•’ æ—¶é—´æˆ³: {timestamp}')

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜checkpointå¤±è´¥ (epoch {epoch_idx}): {str(e)}")
            # å°è¯•ä¿å­˜åˆ°å¤‡ç”¨ä½ç½®
            try:
                backup_path = os.path.join('./saved_backup', f'checkpoint_epoch_{epoch_idx}_backup_{timestamp}.pth')
                os.makedirs('./saved_backup', exist_ok=True)
                torch.save(checkpoint, backup_path)
                self.logger.info(f'âœ… Checkpoint saved to backup location: {backup_path}')
            except Exception as backup_error:
                self.logger.error(f"âŒ å¤‡ä»½checkpointä¹Ÿå¤±è´¥: {str(backup_error)}")

    def load_checkpoint(self, checkpoint_path, resume_epoch=None):
        """
        åŠ è½½æ£€æŸ¥ç‚¹
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
            resume_epoch: æŒ‡å®šè¦åŠ è½½çš„epochï¼Œå¦‚æœä¸ºNoneåˆ™ä»æœ€æ–°checkpointåŠ è½½
        """
        import torch

        try:
            if os.path.exists(checkpoint_path):
                checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)

                # åŠ è½½æ¨¡å‹çŠ¶æ€
                try:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                    self.logger.info(f'âœ… æ¨¡å‹çŠ¶æ€å·²åŠ è½½')
                except Exception as model_error:
                    self.logger.error(f"âŒ åŠ è½½æ¨¡å‹çŠ¶æ€å¤±è´¥: {str(model_error)}")
                    return 0

                # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
                if hasattr(self, 'optimizer') and checkpoint.get('optimizer_state_dict'):
                    try:
                        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                        self.logger.info(f'âœ… ä¼˜åŒ–å™¨çŠ¶æ€å·²åŠ è½½')
                    except Exception as opt_error:
                        self.logger.warning(f"âš ï¸ åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥ï¼Œå°†é‡æ–°åˆå§‹åŒ–: {str(opt_error)}")

                # åŠ è½½æ™ºèƒ½ä½“çŠ¶æ€
                if 'user_agents' in checkpoint and hasattr(self.model, 'user_agents'):
                    try:
                        self.model.user_agents = checkpoint['user_agents']
                        self.logger.info(f'âœ… ç”¨æˆ·æ™ºèƒ½ä½“çŠ¶æ€å·²åŠ è½½: {len(self.model.user_agents)} ä¸ªæ™ºèƒ½ä½“')
                    except Exception as agent_error:
                        self.logger.warning(f"âš ï¸ åŠ è½½ç”¨æˆ·æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")
                
                if 'item_agents' in checkpoint and hasattr(self.model, 'item_agents'):
                    try:
                        self.model.item_agents = checkpoint['item_agents']
                        self.logger.info(f'âœ… ç‰©å“æ™ºèƒ½ä½“çŠ¶æ€å·²åŠ è½½: {len(self.model.item_agents)} ä¸ªæ™ºèƒ½ä½“')
                    except Exception as agent_error:
                        self.logger.warning(f"âš ï¸ åŠ è½½ç‰©å“æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")
                
                if 'embedding_agent' in checkpoint and hasattr(self.model, 'embedding_agent'):
                    try:
                        self.model.embedding_agent = checkpoint['embedding_agent']
                        self.logger.info(f'âœ… åµŒå…¥æ™ºèƒ½ä½“çŠ¶æ€å·²åŠ è½½')
                    except Exception as agent_error:
                        self.logger.warning(f"âš ï¸ åŠ è½½åµŒå…¥æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {str(agent_error)}")

                loaded_epoch = checkpoint.get('epoch', 0)
                timestamp = checkpoint.get('timestamp', 'unknown')
                self.logger.info(f'âœ… Checkpoint loaded from epoch {loaded_epoch} (timestamp: {timestamp})')
                return loaded_epoch
            else:
                self.logger.info(f'ğŸ“ Checkpoint {checkpoint_path} not found, starting from scratch')
                return 0

        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½checkpointå¤±è´¥: {str(e)}")
            self.logger.info(f'ğŸ“ å°†ä»å¤´å¼€å§‹è®­ç»ƒ')
            return 0
