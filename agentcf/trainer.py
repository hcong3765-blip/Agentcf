# ========== å¯¼å…¥æ¨¡å—éƒ¨åˆ† ==========
import os, numpy as np                            # åŸºç¡€åº“
from tqdm import tqdm                             # è¿›åº¦æ¡
import torch                                      # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
from recbole.trainer import Trainer               # RecBoleåŸºç¡€è®­ç»ƒå™¨
from recbole.utils import EvaluatorType, set_color, early_stopping, dict2str, get_gpu_usage
from recbole.data.interaction import Interaction  # RecBoleäº¤äº’æ•°æ®ç±»
from time import time                             # æ—¶é—´åŠŸèƒ½

class LanguageLossTrainer(Trainer):
    """
    è¯­è¨€æŸå¤±è®­ç»ƒå™¨ï¼šç»§æ‰¿è‡ªRecBoleçš„Trainerç±»
    ğŸ’¡è¯­æ³•è§£é‡Šï¼šclass ClassName(ParentClass)è¡¨ç¤ºç±»ç»§æ‰¿
    ä¸“é—¨ç”¨äºå¤„ç†åŸºäºè¯­è¨€æ¨¡å‹çš„æ¨èç³»ç»Ÿè®­ç»ƒ
    """
    
    def __init__(self, config, model, dataset):
        """
        åˆå§‹åŒ–å‡½æ•°
        ğŸ’¡è¯­æ³•è§£é‡Šï¼š__init__æ˜¯Pythonçš„æ„é€ å‡½æ•°ï¼Œåˆ›å»ºå¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨
        """
        super().__init__(config, model)           # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šsuper()è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼Œä¿æŒç»§æ‰¿é“¾çš„å®Œæ•´æ€§
        
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°
        self.sampled_user_suffix = config['sampled_user_suffix']    # å€™é€‰ç”Ÿæˆæ¨¡å‹åç¼€
        self.recall_budget = config['recall_budget']                # å€™é€‰é›†å¤§å°ï¼Œé»˜è®¤20
        self.fix_pos = config['fix_pos']                            # æ­£æ ·æœ¬ä½ç½®ï¼Œé»˜è®¤-1
        
        # åŠ è½½å·²é€‰æ‹©çš„ç‰©å“
        self.user2sampled_item = self.load_selected_items(config, dataset)

    def load_selected_items(self, config, dataset):
        """
        åŠ è½½ç”¨æˆ·çš„é¢„é€‰ç‰©å“åˆ—è¡¨
        è¿™ä¸ªå‡½æ•°è¯»å–æ–‡ä»¶ï¼Œå»ºç«‹ç”¨æˆ·åˆ°å€™é€‰ç‰©å“çš„æ˜ å°„
        """
        # æ„é€ é‡‡æ ·ç‰©å“æ–‡ä»¶è·¯å¾„
        sampled_item_file = os.path.join(config['data_path'], f'{config["dataset"]}.{self.sampled_user_suffix}')
        
        # è·å–ç”¨æˆ·å’Œç‰©å“çš„tokenæ˜ å°„
        user_token2id = dataset.field2token_id['user_id']     # ç”¨æˆ·tokenåˆ°IDçš„æ˜ å°„
        item_token2id = dataset.field2token_id['item_id']     # ç‰©å“tokenåˆ°IDçš„æ˜ å°„
        
        user2sampled_item = {}                    # ç”¨æˆ·åˆ°é‡‡æ ·ç‰©å“çš„å­—å…¸
        
        # è¯»å–æ–‡ä»¶å¹¶è§£æ
        with open(sampled_item_file, 'r', encoding='utf-8') as file:
            for line in file:                     # é€è¡Œè¯»å–
                uid, iid_list = line.strip().split('\t')              # æŒ‰åˆ¶è¡¨ç¬¦åˆ†å‰²
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼šsplit('\t')æŒ‰åˆ¶è¡¨ç¬¦åˆ†å‰²å­—ç¬¦ä¸²ï¼Œstrip()å»é™¤é¦–å°¾ç©ºç™½
                user2sampled_item[user_token2id[uid]] = [item_token2id[_] for _ in iid_list.split(' ')]
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼šåˆ—è¡¨æ¨å¯¼å¼[expression for item in iterable]
        
        return user2sampled_item

    @torch.no_grad()                             # è£…é¥°å™¨ï¼šç¦ç”¨æ¢¯åº¦è®¡ç®—
    def evaluate(self, eval_data, load_best_model=True, model_file=None, show_progress=False):
        """
        è¯„ä¼°å‡½æ•°ï¼šè®¡ç®—æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
        ğŸ’¡è¯­æ³•è§£é‡Šï¼š@torch.no_grad()æ˜¯è£…é¥°å™¨ï¼Œè¡¨ç¤ºå‡½æ•°å†…ä¸è®¡ç®—æ¢¯åº¦ï¼ˆèŠ‚çœå†…å­˜ï¼‰
        """
        eval_func = self._full_sort_batch_eval    # é€‰æ‹©è¯„ä¼°å‡½æ•°
        
        # å¦‚æœéœ€è¦åŠ è½½æœ€ä½³æ¨¡å‹
        if load_best_model:
            checkpoint_file = model_file or self.saved_model_file  # ä½¿ç”¨æŒ‡å®šæ–‡ä»¶æˆ–é»˜è®¤æ–‡ä»¶
            checkpoint = torch.load(checkpoint_file, map_location=self.device)  # åŠ è½½æ£€æŸ¥ç‚¹
            # ğŸ’¡è¯­æ³•è§£é‡Šï¼šmap_locationæŒ‡å®šåŠ è½½åˆ°çš„è®¾å¤‡ï¼Œé¿å…GPU/CPUå†²çª
            
            self.model.load_state_dict(checkpoint["state_dict"])     # åŠ è½½æ¨¡å‹å‚æ•°
            self.model.load_other_parameter(checkpoint.get("other_parameter"))  # åŠ è½½å…¶ä»–å‚æ•°
            
            message_output = "Loading model structure and parameters from {}".format(checkpoint_file)
            self.logger.info(message_output)

        self.model.eval()                         # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šmodel.eval()å…³é—­dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
        
        if self.config["eval_type"] == EvaluatorType.RANKING:
            self.tot_item_num = eval_data._dataset.item_num

        # åˆ›å»ºè¿›åº¦æ¡ï¼ˆå¦‚æœéœ€è¦æ˜¾ç¤ºï¼‰
        iter_data = (
            tqdm(eval_data, total=len(eval_data), ncols=100, desc=set_color(f"Evaluate   ", "pink"))
            if show_progress else eval_data
        )
        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šä¸‰å…ƒè¿ç®—ç¬¦ A if condition else B

        # å¼€å§‹è¯„ä¼°å¾ªç¯
        for batch_idx, batched_data in enumerate(iter_data):
            interaction, history_index, positive_u, positive_i = batched_data
            
            sampled_items = []                    # å­˜å‚¨é‡‡æ ·ç‰©å“
            for i in range(len(interaction)):     # éå†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªç”¨æˆ·
                user_id = int(interaction['user_id'][i].item())  # è·å–ç”¨æˆ·ID
                # ğŸ’¡è¯­æ³•è§£é‡Šï¼š.item()å°†tensorè½¬æ¢ä¸ºPythonæ ‡é‡
                sampled_item = self.user2sampled_item[user_id]   # è·å–ç”¨æˆ·çš„å€™é€‰ç‰©å“
                sampled_items.append(sampled_item)
            
            sampled_items = torch.LongTensor(sampled_items)      # è½¬æ¢ä¸ºtensor

            # å¤„ç†ground truthï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if self.config['has_gt']:
                self.logger.info('Has ground truth')
                idxs = torch.LongTensor(sampled_items)
                
                # ä»å€™é€‰ä¸­ç§»é™¤æ­£æ ·æœ¬ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
                for i in range(idxs.shape[0]):
                    if positive_i[i] in idxs[i]:               # å¦‚æœæ­£æ ·æœ¬åœ¨å€™é€‰ä¸­
                        pr = idxs[i].cpu().numpy().tolist().index(positive_i[i].item())
                        # ğŸ’¡è¯­æ³•è§£é‡Šï¼šé“¾å¼è°ƒç”¨ tensor.cpu().numpy().tolist()
                        idxs[i][pr:-1] = torch.clone(idxs[i][pr+1:])  # ç§»é™¤æ­£æ ·æœ¬
                
                # æˆªå–åˆ°é¢„ç®—å¤§å°
                idxs = idxs[:,:self.recall_budget - 1]
                
                # æ ¹æ®å›ºå®šä½ç½®è®¾ç½®é‡æ–°æ’å…¥æ­£æ ·æœ¬
                if self.fix_pos == -1 or self.fix_pos == self.recall_budget - 1:
                    idxs = torch.cat([idxs, positive_i.unsqueeze(-1)], dim=-1).numpy()
                    # ğŸ’¡è¯­æ³•è§£é‡Šï¼štorch.cat()æ‹¼æ¥tensorï¼Œunsqueeze(-1)å¢åŠ æœ€åä¸€ä¸ªç»´åº¦
                elif self.fix_pos == 0:
                    idxs = torch.cat([positive_i.unsqueeze(-1), idxs], dim=-1).numpy()
                else:
                    idxs_a, idxs_b = torch.split(idxs, (self.fix_pos, self.recall_budget - 1 - self.fix_pos), dim=-1)
                    # ğŸ’¡è¯­æ³•è§£é‡Šï¼štorch.split()æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²tensor
                    idxs = torch.cat([idxs_a, positive_i.unsqueeze(-1), idxs_b], dim=-1).numpy()
            else:
                self.logger.info('Does not have ground truth.')
                idxs = torch.LongTensor(self.sampled_items)
                idxs = idxs[:,:self.recall_budget].numpy()

            # å¦‚æœéœ€è¦éšæœºæ‰“ä¹±ground truthä½ç½®
            if self.fix_pos == -1:
                self.logger.info('Shuffle ground truth')
                for i in range(idxs.shape[0]):
                    np.random.shuffle(idxs[i])    # éšæœºæ‰“ä¹±æ•°ç»„

            idxs = torch.LongTensor(idxs)
            
            # æ‰§è¡Œæ‰¹æ¬¡è¯„ä¼°
            interaction, scores, positive_u, positive_i = eval_func(batched_data, idxs)
            
            # æ”¶é›†è¯„ä¼°ç»“æœ
            self.eval_collector.eval_batch_collect(scores, interaction, positive_u, positive_i)
        
        # æ¨¡å‹æ”¶é›†å’Œæœ€ç»ˆè¯„ä¼°
        self.eval_collector.model_collect(self.model)
        struct = self.eval_collector.get_data_struct()
        result = self.evaluator.evaluate(struct)
        self.wandblogger.log_eval_metrics(result, head="eval")
        
        return result

    def _full_sort_batch_eval(self, batched_data, sampled_items):
        """
        å…¨æ’åºæ‰¹æ¬¡è¯„ä¼°ï¼šå¯¹å€™é€‰ç‰©å“è¿›è¡Œæ‰“åˆ†æ’åº
        """
        interaction, history_index, positive_u, positive_i = batched_data
        
        try:
            # å°è¯•ä½¿ç”¨æ¨¡å‹çš„å…¨æ’åºé¢„æµ‹åŠŸèƒ½
            scores = self.model.full_sort_predict(interaction.to(self.device), sampled_items.to(self.device))
        except NotImplementedError:
            # å¦‚æœæ¨¡å‹æ²¡æœ‰å®ç°å…¨æ’åºï¼Œåˆ™ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            inter_len = len(interaction)
            new_inter = interaction.to(self.device).repeat_interleave(self.tot_item_num)
            # ğŸ’¡è¯­æ³•è§£é‡Šï¼šrepeat_interleave()é‡å¤å¼ é‡å…ƒç´ 
            batch_size = len(new_inter)
            new_inter.update(self.item_tensor.repeat(inter_len))

            # æ ¹æ®æ‰¹æ¬¡å¤§å°é€‰æ‹©é¢„æµ‹æ–¹å¼
            if batch_size <= self.test_batch_size:
                scores = self.model.predict(new_inter)
            else:
                scores = self._spilt_predict(new_inter, batch_size)

        # é‡å¡‘åˆ†æ•°çŸ©é˜µ
        scores = scores.view(-1, self.tot_item_num)
        scores[:, 0] = -np.inf                    # å°†paddingé¡¹è®¾ä¸ºè´Ÿæ— ç©·
        
        # å±è”½å†å²äº¤äº’ç‰©å“
        if history_index is not None:
            scores[history_index] = -np.inf
        
        return interaction, scores, positive_u, positive_i

    def fit(self, train_data, valid_data=None, verbose=True, saved=True, show_progress=False, callback_fn=None, resume_epoch=None):
        """
        è®­ç»ƒå‡½æ•°ï¼šæ‰§è¡Œæ¨¡å‹è®­ç»ƒè¿‡ç¨‹
        ğŸ’¡è¿™æ˜¯ç®€åŒ–ç‰ˆçš„è®­ç»ƒå‡½æ•°ï¼Œä¸»è¦ç”¨äºAgentCFçš„ç‰¹æ®Šè®­ç»ƒéœ€æ±‚
        Args:
            resume_epoch: ä»æŒ‡å®šepochå¼€å§‹è®­ç»ƒï¼Œå¦‚æœä¸ºNoneåˆ™ä»å¤´å¼€å§‹
        """
        # è®¾ç½®èµ·å§‹epoch
        start_epoch = resume_epoch if resume_epoch is not None else self.start_epoch

        # å¦‚æœå·²ç»è®­ç»ƒå®Œæˆä¸”éœ€è¦ä¿å­˜
        if saved and start_epoch >= self.epochs:
            self._save_checkpoint(-1, verbose=verbose)

        # æ•°æ®æ”¶é›†
        self.eval_collector.data_collect(train_data)

        # åŠ¨æ€è´Ÿé‡‡æ ·è®¾ç½®
        if self.config["train_neg_sample_args"].get("dynamic", False):
            train_data.get_model(self.model)

        valid_step = 0

        # è®­ç»ƒå¾ªç¯
        for epoch_idx in range(start_epoch, self.epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = self._train_epoch(train_data, epoch_idx, show_progress=show_progress)

            # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœ‰save_checkpointæ–¹æ³•ï¼‰
            if hasattr(self, 'save_checkpoint'):
                self.save_checkpoint(epoch_idx, verbose=verbose)
            elif saved:
                # å¦‚æœæ²¡æœ‰save_checkpointæ–¹æ³•ï¼Œæ‰‹åŠ¨ä¿å­˜
                self._manual_save_checkpoint(epoch_idx, verbose=verbose)

    def _train_epoch(self, train_data, epoch_idx, loss_func=None, show_progress=False):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        ğŸ’¡epochæ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„æ¦‚å¿µï¼Œè¡¨ç¤ºå¯¹æ•´ä¸ªè®­ç»ƒé›†è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„éå†
        """
        self.model.train()                        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        loss_func = loss_func or self.model.calculate_loss  # é€‰æ‹©æŸå¤±å‡½æ•°
        total_loss = None

        # åˆ›å»ºæ•°æ®è¿­ä»£å™¨ï¼ˆå¸¦æˆ–ä¸å¸¦è¿›åº¦æ¡ï¼‰
        iter_data = (
            tqdm(train_data, total=len(train_data), ncols=100, 
                 desc=set_color(f"Train {epoch_idx:>5}", "pink"))
            if show_progress else train_data
        )

        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒçš„epoch
        if not self.config["single_spec"] and train_data.shuffle:
            train_data.sampler.set_epoch(epoch_idx)

        # è®­ç»ƒå¾ªç¯
        for batch_idx, interaction in enumerate(iter_data):
            interaction = interaction.to(self.device)  # å°†æ•°æ®ç§»åˆ°æŒ‡å®šè®¾å¤‡
            
            # æ˜¾ç¤ºGPUä½¿ç”¨æƒ…å†µ
            if self.gpu_available and show_progress:
                iter_data.set_postfix_str(
                    set_color("GPU RAM: " + get_gpu_usage(self.device), "yellow")
                )
            
            # è®¡ç®—æŸå¤±ï¼ˆè¿™é‡Œè°ƒç”¨æ¨¡å‹çš„calculate_lossæ–¹æ³•ï¼‰
            loss_func(interaction)

        return total_loss

    def _manual_save_checkpoint(self, epoch_idx, verbose=True):
        """
        æ‰‹åŠ¨ä¿å­˜æ£€æŸ¥ç‚¹
        """
        import os
        import torch

        # åˆ›å»ºcheckpointç›®å½•
        checkpoint_dir = os.path.join(self.config['checkpoint_dir'], self.config['model'])
        os.makedirs(checkpoint_dir, exist_ok=True)

        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch_idx}.pth')
        checkpoint = {
            'epoch': epoch_idx,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': getattr(self, 'optimizer', {}).state_dict() if hasattr(self, 'optimizer') else None,
            'config': self.config,
        }

        torch.save(checkpoint, checkpoint_path)

        if verbose:
            self.logger.info(f'Checkpoint saved to {checkpoint_path}')

    def load_checkpoint(self, checkpoint_path, resume_epoch=None):
        """
        åŠ è½½æ£€æŸ¥ç‚¹
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
            resume_epoch: æŒ‡å®šè¦åŠ è½½çš„epochï¼Œå¦‚æœä¸ºNoneåˆ™ä»æœ€æ–°checkpointåŠ è½½
        """
        import torch

        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])

            if hasattr(self, 'optimizer') and checkpoint.get('optimizer_state_dict'):
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

            loaded_epoch = checkpoint.get('epoch', 0)
            self.logger.info(f'Loaded checkpoint from epoch {loaded_epoch}')
            return loaded_epoch
        else:
            self.logger.info(f'Checkpoint {checkpoint_path} not found, starting from scratch')
            return 0
