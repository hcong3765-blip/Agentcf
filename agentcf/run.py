# ========== å¯¼å…¥æ¨¡å—éƒ¨åˆ† ==========
import sys                                          # ç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼ˆå¦‚å‘½ä»¤è¡Œå‚æ•°ï¼‰
import os                                           # æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„æ£€æŸ¥ï¼‰
from logging import getLogger                       # æ—¥å¿—è®°å½•å™¨ï¼Œç”¨äºè¾“å‡ºç¨‹åºè¿è¡Œä¿¡æ¯
import argparse                                     # å‘½ä»¤è¡Œå‚æ•°è§£æå™¨ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥çš„å‚æ•°
from recbole.config import Config                   # RecBoleæ¡†æ¶çš„é…ç½®ç®¡ç†å™¨
from recbole.data import create_dataset, data_preparation  # RecBoleçš„æ•°æ®é›†åˆ›å»ºå’Œé¢„å¤„ç†
from recbole.data.transform import construct_transform     # RecBoleçš„æ•°æ®å˜æ¢æ„é€ å™¨
from recbole.utils import init_logger, get_trainer, init_seed, set_color, get_flops  # RecBoleå·¥å…·å‡½æ•°
from trainer import LanguageLossTrainer  # è‡ªå®šä¹‰è®­ç»ƒå™¨
from utils import get_model                         # è‡ªå®šä¹‰å·¥å…·å‡½æ•°ï¼šåŠ¨æ€æ¨¡å‹åŠ è½½
from dataset import BPRDataset, ITEMBPRDataset     # è‡ªå®šä¹‰æ•°æ®é›†ç±»

def run_baseline(model_name, dataset_name, **kwargs):
    """
    æ ¸å¿ƒå‡½æ•°ï¼šè¿è¡ŒåŸºçº¿æ¨¡å‹çš„å®Œæ•´æµç¨‹
    å‚æ•°ï¼š
    - model_name: æ¨¡å‹åç§°ï¼ˆå¦‚'AgentCF'ï¼‰
    - dataset_name: æ•°æ®é›†åç§°ï¼ˆå¦‚'ml-1m'ï¼‰  
    - **kwargs: å…¶ä»–å¯é€‰å‚æ•°
    """
    
    # ========== ç¬¬ä¸€æ­¥ï¼šé…ç½®æ–‡ä»¶å‡†å¤‡ ==========
    props = ['props/overall.yaml', f'props/{model_name}.yaml', f'props/{dataset_name}.yaml']
    print(props)                                    # ğŸ›è°ƒè¯•ç‚¹ï¼šæŸ¥çœ‹é…ç½®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    # ğŸ’¡è§£é‡Šï¼šé…ç½®æ–‡ä»¶æŒ‰ä¼˜å…ˆçº§åŠ è½½ï¼Œåé¢çš„ä¼šè¦†ç›–å‰é¢çš„åŒåé…ç½®
    
    # ========== ç¬¬äºŒæ­¥ï¼šåŠ¨æ€æ¨¡å‹åŠ è½½ ==========  
    model_class = get_model(model_name)             # è°ƒç”¨utils.pyä¸­çš„get_modelå‡½æ•°
    # ğŸ’¡è§£é‡Šï¼šæ ¹æ®æ¨¡å‹ååŠ¨æ€å¯¼å…¥å¯¹åº”çš„æ¨¡å‹ç±»
    
    # ========== ç¬¬ä¸‰æ­¥ï¼šé…ç½®å¯¹è±¡åˆå§‹åŒ– ==========
    config = Config(
        model=model_class,                          # æ¨¡å‹ç±»å¯¹è±¡
        dataset=dataset_name,                       # æ•°æ®é›†åç§°
        config_file_list=props,                     # é…ç½®æ–‡ä»¶åˆ—è¡¨
        config_dict=kwargs,                         # é¢å¤–é…ç½®å‚æ•°
    )
    init_seed(config["seed"], config["reproducibility"])  # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
    
    # ========== ç¬¬å››æ­¥ï¼šæ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ– ==========
    init_logger(config)                             # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = getLogger()                            # è·å–æ—¥å¿—è®°å½•å™¨
    logger.info(sys.argv)                           # è®°å½•å‘½ä»¤è¡Œå‚æ•°
    logger.info(config)                             # è®°å½•é…ç½®ä¿¡æ¯
    
    # ========== ç¬¬äº”æ­¥ï¼šæ•°æ®é›†é€‰æ‹©å’Œåˆ›å»º ==========
    # ğŸ’¡è§£é‡Šï¼šæ ¹æ®ä¸åŒæ¨¡å‹é€‰æ‹©ä¸åŒçš„æ•°æ®é›†å¤„ç†æ–¹å¼
    if model_name == 'BPR' or model_name == 'UUPretrain' or model_name == 'ReRec' or model_name == 'AllReRec' or model_name == 'IITest' or model_name == 'TestGames' or model_name == 'SparseReRec'\
            or model_name in ['TestPantry', 'TestOffice', 'IITestDiag', 'IITestDiagNew', 'TestOfficeBPR', 'TestOfficeUUPretrain','UserReRec','AgentCF']:
        dataset = BPRDataset(config)                # ä½¿ç”¨è‡ªå®šä¹‰BPRæ•°æ®é›†
    elif model_name in ['UUTest','UUTestDiag','TestOfficeUUTest']:
        dataset = ITEMBPRDataset(config)            # ä½¿ç”¨ç‰©å“BPRæ•°æ®é›†
    else:
        dataset = create_dataset(config)            # ä½¿ç”¨RecBoleé»˜è®¤æ•°æ®é›†åˆ›å»º

    logger.info(dataset)                            # è®°å½•æ•°æ®é›†ä¿¡æ¯

    # ========== ç¬¬å…­æ­¥ï¼šæ•°æ®åˆ†å‰² ==========
    train_data, valid_data, test_data = data_preparation(config, dataset)
    # ğŸ’¡è§£é‡Šï¼šå°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ï¼Œé€šå¸¸æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²

    # ========== ç¬¬ä¸ƒæ­¥ï¼šæ¨¡å‹å®ä¾‹åŒ– ==========
    init_seed(config["seed"] + config["local_rank"], config["reproducibility"])  # å†æ¬¡è®¾ç½®ç§å­
    model = model_class(config, train_data._dataset).to(config["device"])       # åˆ›å»ºæ¨¡å‹å¹¶ç§»åˆ°æŒ‡å®šè®¾å¤‡
    logger.info(model)                              # è®°å½•æ¨¡å‹ç»“æ„ä¿¡æ¯

    # ========== ç¬¬å…«æ­¥ï¼šæ•°æ®å˜æ¢æ„é€  ==========
    transform = construct_transform(config)         # æ„é€ æ•°æ®å˜æ¢ï¼ˆå¦‚å½’ä¸€åŒ–ç­‰ï¼‰
    
    # ========== ç¬¬ä¹æ­¥ï¼šè®­ç»ƒå™¨é€‰æ‹© ==========
    # ğŸ’¡è§£é‡Šï¼šä¸åŒæ¨¡å‹éœ€è¦ä¸åŒçš„è®­ç»ƒç­–ç•¥
    if model_name in ['SASRec','BPRMF']:
        trainer = get_trainer(config["MODEL_TYPE"], config["model"])(config, model)  # RecBoleé»˜è®¤è®­ç»ƒå™¨
    elif model_name in ['UUTest', 'UUTestDiag','TestOfficeUUTest','TestOfficeUUTestDiag']:
        trainer = LanguageLossTrainer(config,model,dataset)                          # è¯­è¨€æŸå¤±è®­ç»ƒå™¨
    else:
        trainer = LanguageLossTrainer(config,model,dataset)                          # è¯­è¨€æŸå¤±è®­ç»ƒå™¨

    # ========== ç¬¬åæ­¥ï¼šæ¨¡å‹è®­ç»ƒ ==========
    if not config['test_only']:                     # å¦‚æœä¸æ˜¯ä»…æµ‹è¯•æ¨¡å¼
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰resume_epochå‚æ•°
            resume_epoch = kwargs.get('resume_epoch', None)
            if resume_epoch is not None:
                # åŠ è½½checkpoint
                checkpoint_path = kwargs.get('checkpoint_path', f'./saved/{model_name}/checkpoint_epoch_{resume_epoch-1}.pth')
                loaded_epoch = trainer.load_checkpoint(checkpoint_path)
                if loaded_epoch != resume_epoch - 1:
                    logger.warning(f"Loaded epoch {loaded_epoch}, but expected {resume_epoch-1}")
                resume_epoch = loaded_epoch + 1

            trainer.fit(train_data, valid_data, saved=True, show_progress=config["show_progress"], resume_epoch=resume_epoch)
            # ğŸ’¡è§£é‡Šï¼šå¼€å§‹è®­ç»ƒè¿‡ç¨‹ï¼Œsaved=Trueè¡¨ç¤ºä¿å­˜æœ€ä½³æ¨¡å‹
            logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            # å³ä½¿è®­ç»ƒå¤±è´¥ä¹Ÿç»§ç»­è¿›è¡Œè¯„ä¼°

    # ========== ç¬¬åä¸€æ­¥ï¼šæ¨¡å‹è¯„ä¼° ==========
    try:
        if config['test_only']:
            # ä»…è¯„ä¼°æ¨¡å¼ï¼šéœ€è¦åŠ è½½è®­ç»ƒåçš„æ¨¡å‹å’Œæ™ºèƒ½ä½“çŠ¶æ€
            logger.info("ğŸ¯ ä»…è¯„ä¼°æ¨¡å¼ï¼šåŠ è½½è®­ç»ƒåçš„æ¨¡å‹å’Œæ™ºèƒ½ä½“çŠ¶æ€")
            
            # åŠ¨æ€æ„å»ºæƒé‡æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒæ—¶é—´æˆ³ç›®å½•
            checkpoint_dir = config['checkpoint_dir'] if 'checkpoint_dir' in config else './saved'
            model_base_dir = os.path.join(checkpoint_dir, model_name)
            
            # æŸ¥æ‰¾æœ€æ–°çš„checkpointæ–‡ä»¶
            model_file = None
            if os.path.exists(model_base_dir):
                # æŸ¥æ‰¾æ‰€æœ‰run_*ç›®å½•
                run_dirs = [d for d in os.listdir(model_base_dir) if d.startswith('run_')]
                if run_dirs:
                    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
                    run_dirs.sort(reverse=True)
                    latest_run_dir = run_dirs[0]
                    checkpoint_file = os.path.join(model_base_dir, latest_run_dir, 'checkpoint_epoch_0.pth')
                    if os.path.exists(checkpoint_file):
                        model_file = checkpoint_file
                        logger.info(f"âœ… æ‰¾åˆ°æœ€æ–°æƒé‡æ–‡ä»¶: {model_file}")
                    else:
                        logger.warning(f"âš ï¸ æœ€æ–°runç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°checkpointæ–‡ä»¶: {checkpoint_file}")
                else:
                    # å¦‚æœæ²¡æœ‰run_*ç›®å½•ï¼Œå°è¯•æ—§æ ¼å¼
                    old_checkpoint_file = os.path.join(model_base_dir, 'checkpoint_epoch_0.pth')
                    if os.path.exists(old_checkpoint_file):
                        model_file = old_checkpoint_file
                        logger.info(f"âœ… æ‰¾åˆ°æ—§æ ¼å¼æƒé‡æ–‡ä»¶: {model_file}")
                    else:
                        logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•checkpointæ–‡ä»¶")
            else:
                logger.warning(f"âš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_base_dir}")
            
            # æ ¹æ®æ˜¯å¦æ‰¾åˆ°æƒé‡æ–‡ä»¶å†³å®šè¯„ä¼°ç­–ç•¥
            if model_file:
                # åŠ è½½æƒé‡æ–‡ä»¶ï¼ˆåŒ…å«è®­ç»ƒåçš„æ™ºèƒ½ä½“çŠ¶æ€ï¼‰
                test_result = trainer.evaluate(test_data, model_file=model_file,
                                              load_best_model=True, show_progress=config["show_progress"])
            else:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æƒé‡æ–‡ä»¶")
                logger.info("ğŸ”„ ä½¿ç”¨å½“å‰çŠ¶æ€è¿›è¡Œæµ‹è¯•")
                # å¦‚æœæ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å½“å‰çŠ¶æ€ï¼ˆå¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ï¼‰
                test_result = trainer.evaluate(test_data, load_best_model=False, 
                                              show_progress=config["show_progress"])
        else:
            # è®­ç»ƒ+è¯„ä¼°æ¨¡å¼ï¼šä½¿ç”¨è®­ç»ƒåçš„æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆå½“å‰å†…å­˜ä¸­çš„çŠ¶æ€ï¼‰
            logger.info("ğŸ¯ è®­ç»ƒ+è¯„ä¼°æ¨¡å¼ï¼šä½¿ç”¨è®­ç»ƒåçš„æ™ºèƒ½ä½“çŠ¶æ€")
            test_result = trainer.evaluate(test_data, load_best_model=False, 
                                          show_progress=config["show_progress"])
        
        print(test_result)                              # ğŸ›è°ƒè¯•ç‚¹ï¼šæ‰“å°æµ‹è¯•ç»“æœ
        logger.info("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")

    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        test_result = {"error": "è¯„ä¼°å¤±è´¥", "details": str(e)}

    logger.info(set_color("test result", "yellow") + f": {test_result}")  # å½©è‰²æ—¥å¿—è¾“å‡º
    
    # ========== ç¬¬åäºŒæ­¥ï¼šè¿”å›ç»“æœ ==========
    return model_name, dataset_name, {
        "test_result": test_result,
    }

# ========== ä¸»ç¨‹åºå…¥å£ ==========
if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", "-m", type=str, default="SASRec", help="name of models")
    parser.add_argument("--dataset", "-d", type=str, default="ml-1m", help="name of datasets")
    parser.add_argument("--resume_epoch", "-r", type=int, default=None, help="resume training from specific epoch")
    parser.add_argument("--checkpoint_path", "-c", type=str, default=None, help="path to checkpoint file")

    args, _ = parser.parse_known_args()             # è§£æå‘½ä»¤è¡Œå‚æ•°

    # ğŸš€ å¯åŠ¨æ ¸å¿ƒæµç¨‹
    kwargs = {}
    if args.resume_epoch is not None:
        kwargs['resume_epoch'] = args.resume_epoch
    if args.checkpoint_path is not None:
        kwargs['checkpoint_path'] = args.checkpoint_path

    run_baseline(args.model, args.dataset, **kwargs)